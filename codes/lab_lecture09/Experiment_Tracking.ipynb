{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiL3_PU0JrC1"
   },
   "source": [
    "## Experiment Tracking \n",
    "\n",
    "In development of machine learning, we need to track all of experiments. Terefore, a proper process is required. Here, this notebook showcases how we use one of tools called MLFlow. \n",
    "\n",
    "\n",
    "\n",
    "1. Train a linear regression model\n",
    "\n",
    "2. Package the code that trains the model in a reusable and reproducible model format\n",
    "\n",
    "\n",
    "This tutorial uses a dataset to predict the quality of wine based on quantitative features like the wine’s “fixed acidity”, “pH”, “residual sugar”, and so on. The dataset is from UCI’s machine learning repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3NDv17hWJtnA"
   },
   "outputs": [],
   "source": [
    "!pip install mlflow -q\n",
    "!pip install pyngrok -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pR5PYOy5KVMS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "from argparse import Namespace\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    # Read the wine-quality csv file from the URL\n",
    "    csv_url = (\n",
    "        \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    )\n",
    "    try:\n",
    "        data = pd.read_csv(csv_url, sep=\";\")\n",
    "    except Exception as e:\n",
    "        print(\"Unable to download training & test CSV, check your internet connection. Error: %s\")\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdzBiCXrYzXs",
    "outputId": "38ac8909-c36a-4686-b269-3a438d2ce38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEQ_xT52Y1g-",
    "outputId": "50bf0c12-60b4-4c9c-ab16-d79a5d00bd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XGXxf15aTyZz"
   },
   "outputs": [],
   "source": [
    "# Set tracking URI\n",
    "MODEL_REGISTRY = Path(\"experiments\")\n",
    "Path(MODEL_REGISTRY).mkdir(exist_ok=True) # create experiments dir\n",
    "mlflow.set_tracking_uri(\"file://\" + str(MODEL_REGISTRY.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Slp-SzjZUlJD",
    "outputId": "68593359-ce3a-47c1-e25c-0a2a77a9cc8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xm9WZ5azgCBF"
   },
   "outputs": [],
   "source": [
    "!ls /content/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kbnAxUEqLmFk"
   },
   "outputs": [],
   "source": [
    "def train_lr(args, df):\n",
    "    \"\"\"Train a LR using specific arguments.\"\"\"\n",
    "\n",
    "    # Set seeds\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Get data splits\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(df)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "\n",
    "    # Initialize model\n",
    "    alpha    = args.alpha\n",
    "    l1_ratio = args.l1_ratio\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    lr.fit(train_x, train_y)\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "    # Test the model\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "    # Evaluate (simple)\n",
    "    performance = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "    return {\n",
    "        \"args\": args,\n",
    "        \"model\": lr,\n",
    "        \"performance\": performance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2r6LsVeAQ837"
   },
   "outputs": [],
   "source": [
    "def mlexp_track(args, df):\n",
    "  # Tracking\n",
    "  with mlflow.start_run() as run:\n",
    "    df = load_data()\n",
    "    # Train & evaluate\n",
    "    artifacts = train_lr(args=args, df=df)\n",
    "    # Log key metrics\n",
    "    mlflow.log_metrics({\"RMSE\": artifacts[\"performance\"][\"RMSE\"]})\n",
    "    mlflow.log_metrics({\"MAE\": artifacts[\"performance\"][\"MAE\"]})\n",
    "    mlflow.log_metrics({\"R2\": artifacts[\"performance\"][\"R2\"]})\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    # Model registry does not work with file store\n",
    "    if tracking_url_type_store != \"file\":\n",
    "          # Register the model\n",
    "          # There are other ways to use the Model Registry, which depends on the use case,\n",
    "          # please refer to the doc for more information:\n",
    "          # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "          mlflow.sklearn.log_model(artifacts['model'], \"model\", registered_model_name=\"ElasticnetWineModel\")\n",
    "    else:\n",
    "          mlflow.sklearn.log_model(artifacts['model'], \"model\")\n",
    "    # Log parameters\n",
    "    mlflow.log_params(vars(artifacts[\"args\"]))\n",
    "    #mlflow.log_param(\"alpha\", artifacts[\"args\"].alpha)\n",
    "    #mlflow.log_param(\"l1_ratio\", artifacts[\"args\"].l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YdEMuub0OfFY"
   },
   "outputs": [],
   "source": [
    "# Specify a list of arguments\n",
    "args_list = [Namespace(alpha=1.5, l1_ratio=0.9,),\n",
    "             Namespace(alpha=0.5, l1_ratio=0.02,),\n",
    "             Namespace(alpha=0.01, l1_ratio=0.5,)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKF7nJbZK6CG",
    "outputId": "57a7d9c3-d47d-41c4-f4cb-47558040381f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/03/18 09:37:56 INFO mlflow.tracking.fluent: Experiment with name 'baselines' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///content/experiments/0', experiment_id='0', lifecycle_stage='active', name='baselines', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1IeEQR3RkLB",
    "outputId": "72b0336c-fdfc-4fa1-8d46-6d2148ad7d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=1.500000, l1_ratio=0.900000):\n",
      "  RMSE: 0.8327481314145982\n",
      "  MAE: 0.6751289812215555\n",
      "  R2: 0.017435513620481347\n",
      "Elasticnet model (alpha=0.500000, l1_ratio=0.020000):\n",
      "  RMSE: 0.7364106074415193\n",
      "  MAE: 0.5673052761841408\n",
      "  R2: 0.23162398391500494\n",
      "Elasticnet model (alpha=0.010000, l1_ratio=0.500000):\n",
      "  RMSE: 0.6778557583356976\n",
      "  MAE: 0.5190564939146215\n",
      "  R2: 0.3489590462840657\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "for args in args_list:\n",
    "  mlexp_track(args, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OZa0TIgmRyGv"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3f_qMPbXshN"
   },
   "source": [
    "### Check experiments' records from UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vIG6Da8RzOB",
    "outputId": "ed68f848-f30d-4aa8-d751-39a755da9d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: https://2a66-34-66-129-152.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
    "get_ipython().system_raw(\"mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri $PWD/experiments/ &\")\n",
    "ngrok.kill()\n",
    "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
    "ngrok.set_auth_token(\"\")\n",
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAgVXqs4X04Q"
   },
   "source": [
    "### Retrieve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwjMv6IKV-FW",
    "outputId": "011acfc5-8917-4467-9dd0-d25ec2438992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             run_id experiment_id    status  \\\n",
      "0  152f5ffbaad841ef98a015028ac4eae8             0  FINISHED   \n",
      "1  7e706301eee14f37b6d766fe82e3c6fe             0  FINISHED   \n",
      "2  8446d297418c4224ac1d5e0d0efaa96b             0  FINISHED   \n",
      "\n",
      "                                        artifact_uri  \\\n",
      "0  file:///content/experiments/0/152f5ffbaad841ef...   \n",
      "1  file:///content/experiments/0/7e706301eee14f37...   \n",
      "2  file:///content/experiments/0/8446d297418c4224...   \n",
      "\n",
      "                        start_time                         end_time  \\\n",
      "0 2022-03-06 00:00:20.494000+00:00 2022-03-06 00:00:23.240000+00:00   \n",
      "1 2022-03-06 00:00:17.418000+00:00 2022-03-06 00:00:20.491000+00:00   \n",
      "2 2022-03-06 00:00:11.552000+00:00 2022-03-06 00:00:17.414000+00:00   \n",
      "\n",
      "   metrics.MAE  metrics.RMSE  metrics.R2 params.alpha params.l1_ratio  \\\n",
      "0     0.519056      0.677856    0.348959         0.01             0.5   \n",
      "1     0.567305      0.736411    0.231624          0.5            0.02   \n",
      "2     0.675129      0.832748    0.017436          1.5             0.9   \n",
      "\n",
      "                             tags.mlflow.source.name tags.mlflow.source.type  \\\n",
      "0  /usr/local/lib/python3.7/dist-packages/ipykern...                   LOCAL   \n",
      "1  /usr/local/lib/python3.7/dist-packages/ipykern...                   LOCAL   \n",
      "2  /usr/local/lib/python3.7/dist-packages/ipykern...                   LOCAL   \n",
      "\n",
      "  tags.mlflow.user                      tags.mlflow.log-model.history  \n",
      "0             root  [{\"run_id\": \"152f5ffbaad841ef98a015028ac4eae8\"...  \n",
      "1             root  [{\"run_id\": \"7e706301eee14f37b6d766fe82e3c6fe\"...  \n",
      "2             root  [{\"run_id\": \"8446d297418c4224ac1d5e0d0efaa96b\"...  \n"
     ]
    }
   ],
   "source": [
    "# Load all runs from experiment\n",
    "experiment_id = mlflow.get_experiment_by_name(\"baselines\").experiment_id\n",
    "all_runs = mlflow.search_runs(experiment_ids=experiment_id, order_by=[\"metric.MAE\", \"metric.R2\"])\n",
    "print (all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LL5xd8GpWEMP"
   },
   "outputs": [],
   "source": [
    "# Load the Best run\n",
    "best_run_id = all_runs.iloc[0].run_id\n",
    "best_run = mlflow.get_run(run_id=best_run_id)\n",
    "model_uri = \"runs:/\" + best_run_id + \"/model\"\n",
    "hh = mlflow.sklearn.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4O2VpCE3X9jd",
    "outputId": "46df3171-40f3-4928-efb4-f3c055634395"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.55755636, 5.43387419, 5.50192246])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.predict(df.drop([\"quality\"], axis=1).iloc[20:23])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment Tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
